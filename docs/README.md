# EduRoll
EduRoll: End-to-End Ethereum zk-Rollup (L1 Contracts, Sequencer, Circuits) Built From Scratch

This project implements a minimal end-to-end ZK-Rollup for tuition payments, designed as a set of decoupled, containerised microservices. The architecture separates L1 (Ethereum) consensus from L2 (EduRoll) computation.

## System Architecture & Operational Flow

[Click to view full size System Overview Diagram](./assets/diagrams/SystemOverview.png)

<a href="./assets/diagrams/SystemOverview.png">
  <img src="./assets/diagrams/SystemOverview.png" alt="System Overview Diagram" width="450"/>
</a>

The system's core design principle is **resilience and scalability**, achieved by using a central **Persistent Database (PostgreSQL)** as the single source of truth and communication hub for all off-chain services.

### Core Components

* **L1 Smart Contracts (Solidity):**
    * **`Rollup.sol`**: The primary L1 contract. It acts as the on-chain "ledger," storing the authoritative L2 state root.
    * **`Verifier.sol`**: A highly efficient contract (auto-generated by `snarkjs`) whose sole purpose is to mathematically verify ZK-SNARK proofs.

* **L2 Off-Chain Services (Rust & Docker):**
    * **`Test Client Container`**: A simulation utility that generates signed L2 transactions (tuition payments) and sends them to the Sequencer.
    * **`Sequencer Container`**: The "gatekeeper" of the L2 network. It receives transactions, validates them, and groups them into ordered batches.
    * **`Prover Container`**: The cryptographic "engine." It generates the ZK-SNARK proof that validates the state transition of a batch.
    * **`Archiver Container`**: A read-only "historian" service that indexes data from the database for external queries (e.g., a block explorer).
    * **`Submitter Container`**: The "finaliser." This service is responsible for sending the proven L2 batches and their proofs to the L1 `Rollup.sol` contract.
    * **`PersistentDB Container`**: * A PostgreSQL database running in its own dedicated Docker container, with its data stored on a persistent Docker volume.
    It acts as the **single source of truth** and the central **communication hub** for all L2 services. Instead of communicating with each other directly (which is brittle), services operate asynchronously by reading and writing to the database.
      * **Flow:**
          1.  The `Sequencer` writes a new batch with a status of `pending_proof`.
          2.  The `Prover` polls the PersistentDB, finds this `pending_proof` batch, generates a proof, and updates the batch's status to `proven`.
          3.  The `Submitter` polls the PersistentDB, finds this `proven` batch, and knows it's time to submit it to L1.

      * **Why such design approach:** This decoupled architecture provides high **resilience** and **fault tolerance**. If the `Prover` crashes, the batch simply remains `pending_proof` in the database, and the service can safely resume its work upon restarting.
---
## System Setup Process
### Phase 1: ZK-Artifact Generation (Compile-Time)

Before the system can run, the ZK-SNARK components are generated from the circuit logic (as shown by the **purple Circuit** arrows):

1.  **Circuit Compilation:** The circuit logic (implemented in both Circom and Noir, although only one is ultimately used) is compiled into its mathematical representation, the **`transfer.r1cs`** (Rank-1 Constraint System).

2.  **Key Generation:** This single `transfer.r1cs` file is used to generate two mathematically-linked components:
    * **L2 Proving Key (`transfer_final.zkey`):** A large (e.g., 100MB) file generated via a trusted setup. In our case, we use **`Groth16`**, although other systems such as PLONK, PLONKish (UltraPLONK), Marlin, or Halo2 can also be used. **Groth16 was chosen because** it provides fast verification and a small Layer-1 **verifier contract**. This proving key is loaded by the **`Prover`** service to *generate* proofs.

      * Below is a table for comparison of available libraries:

| System | Core Features | Trusted Setup | Verifier Cost | Used By |
| :--- | :--- | :--- | :--- | :--- |
| [**Groth16**](https://alinush.github.io/groth16) | Very fast verification; smallest proofs | Circuit-specific | **Lowest** | Filecoin, many Circom projects |
| [**PLONK**](https://eprint.iacr.org/2019/953.pdf) | Universal setup; flexible | Universal | Medium | Aztec 1, early zkSync |
| [**UltraPLONK / TurboPLONK**](https://hackmd.io/@aztec-network/plonk-arithmetiization-air) | Lookup/optimized gates; scalable | Universal | Medium | Polygon zkEVM (variants) |
| [**Marlin**](https://eprint.iacr.org/2019/1047.pdf) | Transparent; succinct | Transparent | Medium | Mina ecosystem |
| [**Halo2**](https://eprint.iacr.org/2019/1021.pdf) | Recursion-friendly; flexible; modern | Transparent | Higher | Zcash, Scroll (with KZG) |
| [**STARKs**](https://eprint.iacr.org/2018/046.pdf) | Fast proving; highly scalable; hash-based | Transparent | High (large proofs) | StarkNet |
| **[Spartan](https://github.com/microsoft/Spartan2) / [HyperPlonk](https://eprint.iacr.org/2022/1355.pdf)** | Modular, research-focused systems | Mixed | Varies | Research prototypes |


* **L1 Verifier (`Verifier.sol`):** A small (e.g., 5KB) Solidity contract generated by `snarkjs`. It is deployed to L1 to *check* proofs.


### Phase 2: Runtime Operational Flow (End-to-End)

This describes how transactions processed on the rollup in batches (a batch is set to contain 100 transactions in this prototype) and then submitted to Layer-1 Ethereum

1.  **Step 1: Ingestion (Data Flow)**
    * The `TEST CLIENT` generates and sends signed L2 transactions to the `SEQUENCER`'s RPC endpoint.

2.  **Step 2: Batching (Data Flow)**
    * The `SEQUENCER` validates the transactions and stores it in the `txs` table of the `PERSISTENTDB`.
    * Periodically, the `SEQUENCER` fetches a list of pending transactions, reads the current state from the `accounts` table, and executes them (using the `execution` and `merkle` crates) to calculate a new **state root**.
    * It writes this new batch (new state root, list of tx hashes, etc.) to the `batches` table, marking it as `pending_proof`.

3.  **Step 3: Proving (Proof Flow)**
    * The `PROVER` is continuously polling the `PersistentDB`. It finds a `pending_proof` batch.
    * It reads the batch data, loads its `transfer_final.zkey`, and generates the ZK-SNARK proof (`a, b, c`) that validates the state transition.
    * The `PROVER` writes this proof back to the `batches` table in the `PersistentDB` and updates the status to `proven`.

4.  **Step 4: Archiving (Data Flow)**
    * In parallel, the `ARCHIVER` is constantly reading the `PersistentDB` (both `txs` and `batches` tables) and indexing them for historical queries. This service does not write or alter the rollup's state.

5.  **Step 5: Submission & Verification (Proof Flow)**
    * The `SUBMITTER` polls the `PersistentDB` and finds a `proven` batch.
    * It reads the proof (`a, b, c`) and the public inputs (the old and new state roots).
    * It submits an L1 transaction to the **`Rollup.sol`** contract, calling the `submitBatch()` function with the proof and public inputs.
    * `Rollup.sol` receives the call and immediately passes the proof data to the **`Verifier.sol`** contract by calling `verifyProof()`.
    * `Verifier.sol` runs the on-chain cryptographic check. If the proof is valid, it returns `true`.
    * `Rollup.sol` receives `true`, requires the check to pass, and updates its internal `stateRoot` variable to the new state root from the batch.

At this point, the L2 batch is officially finalised and secured by L1 consensus.

---

### üìç Documentation Status
This section is under active development. Further details will be added as components are implemented.
